{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H6ty0er_M1m"
      },
      "source": [
        "# Machine Learning: Supervised"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwcohRsf_M1u"
      },
      "source": [
        "## Supervised Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jC6FF14c_M1u"
      },
      "source": [
        "![](https://i163.photobucket.com/albums/t281/kyin_album/m1_1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10qcHkjI_M1v"
      },
      "source": [
        "![](https://i163.photobucket.com/albums/t281/kyin_album/m6.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cszZFWTd_M1v"
      },
      "source": [
        "# <font color=\"blue\"> Project 1: House Price Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqfU8nTm_M1v"
      },
      "source": [
        "In this example, we'll use a linear regression model to predict housing prices based on 1 feature.\n",
        "\n",
        "First, make sure you have scikit-learn installed. You can install it using pip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x2jOAF7i_M1w",
        "outputId": "87b03dbd-9b8a-4ee6-8721-d9a6efb28d4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: You must give at least one requirement to install (see \"pip help install\")\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "pip install   #complete this"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibK6T7q39MGC"
      },
      "source": [
        "To know more about scikit-learn : [Scikit-learn Documentation](https://scikit-learn.org/stable/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA16nJku_M1y"
      },
      "source": [
        "## Step 1: Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZVIZHnG_M1y"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import                                          #complete this\n",
        "from sklearn.model_selection import             #complete this\n",
        "from sklearn.linear_model import                #complete this\n",
        "from sklearn.metrics import                     #complete this\n",
        "\n",
        "# Sample dataset: housing prices (target) based on house size (feature)\n",
        "house_sizes = np.array([550, 600, 650, 700, 750, 800, 850, 900, 950, 1000])\n",
        "prices = np.array([300000, 410000, 530000, 510000, 540000, 610000, 730000, 760000, 830000, 860000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePfW9hvu_M1z"
      },
      "outputs": [],
      "source": [
        "#plot graph prices against house_prices\n",
        "import                                          #complete this\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.scatter(house_sizes, prices, color='', label='Data Points')              #complete this\n",
        "plt.xlabel('')                                              #complete this\n",
        "plt.ylabel('')                                             #complete this\n",
        "plt.title('')                                            #complete this\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_kESJc7_M1z"
      },
      "source": [
        "## Step 2 & 3 : Feature Extraction and Split the data (into training and testing set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AJw9y30_M10"
      },
      "outputs": [],
      "source": [
        "# Reshape the feature array to match the input format required by scikit-learn\n",
        "X =                         #complete this\n",
        "print (X)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test =  (X, prices, test_size= , random_state=42)      #complete this\n",
        "print (X_test)\n",
        "print (y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmmgSpE9_M10"
      },
      "source": [
        "## Step 4: Fit model and predict outcomes [Code]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGZuQoGD_M10"
      },
      "outputs": [],
      "source": [
        "# Create the linear regression model\n",
        "model =                             #complete this\n",
        "\n",
        "# Train the model using the training data\n",
        "model.(X_train, y_train)         #complete this\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.(X_test)      #complete this\n",
        "\n",
        "# Formatting X_test\n",
        "formatted_X_test = [\"%.2f\" % x for x in X_test]\n",
        "print(formatted_X_test)\n",
        "\n",
        "# Formatting y_pred\n",
        "formatted_y_pred = [\"%.2f\" % y for y in y_pred]\n",
        "print(formatted_y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Rua6QZk9MGF"
      },
      "outputs": [],
      "source": [
        "# the following is the equation of the linear regression model\n",
        "\n",
        "# Print the coefficients\n",
        "print(\"Coefficient:\", model.)                 #complete this\n",
        "print(\"Intercept:\", model. )                  #complete this\n",
        "\n",
        "# Construct the equation string\n",
        "equation = f\"y = {model.coef_[0]} * X + {model.intercept_}\"\n",
        "print(\"Linear Regression Equation:\", equation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF7M8hcM_M11"
      },
      "source": [
        "## Step 5: Evaluate the model [Code]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sun9s3g4_M11"
      },
      "outputs": [],
      "source": [
        "# Calculate the Mean Squared Error (MSE) as a measure of the model's performancemse = mean_squared_error(y_test, y_pred)\n",
        "from sklearn.metrics import                     #complete this\n",
        "mse =                                           #complete this\n",
        "\n",
        "\n",
        "# Display the MSE with two decimal places using string formatting\n",
        "formatted_mse = \"%.2f\" % mse\n",
        "print(f\"Mean Squared Error: {formatted_mse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2plqwoLzjGf"
      },
      "source": [
        "# Step 6: Predict unseen data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCyQHYWZx2tu"
      },
      "outputs": [],
      "source": [
        "# Assuming you have a single unseen data point represented as a list\n",
        "unseen_data =                         #complete this\n",
        "\n",
        "# Reshape the unseen_data to a 2D array\n",
        "unseen_data_reshaped = np.array(unseen_data).reshape(1, -1)       #complete this\n",
        "\n",
        "# Predict the target value for the unseen data point\n",
        "predicted_value =                                 #complete this\n",
        "\n",
        "# Print the predicted value\n",
        "print(f\"Predicted Value (RM): {predicted_value[0]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsKvJ8xTIo2w"
      },
      "source": [
        "# Step 7 Store the model in Joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW0nzKL4IsNa"
      },
      "source": [
        "Store the model using joblib or pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAAbnSRDIul4"
      },
      "outputs": [],
      "source": [
        "from joblib import dump, load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncXxyChwIwJ2"
      },
      "outputs": [],
      "source": [
        "dump(model, 'linear_regression_model.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPevzm-EIyi9"
      },
      "source": [
        "Load the model and predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GdCi5FjIxVj"
      },
      "outputs": [],
      "source": [
        "model = load('linear_regression_model.joblib')\n",
        "user_input = int(input (\"Enter house size:\"))\n",
        "input_array = np.array([user_input]).reshape(-1, 1)\n",
        "predicted_price = model.predict(input_array)\n",
        "print(f\"Predicted Value: {predicted_price[0]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9urnM8Y8I0di"
      },
      "source": [
        "# Deployment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohU5zH11I5Er"
      },
      "source": [
        "You can deploy into Streamlit or Flask.\n",
        "Streamlit is an open-source app framework specifically designed for Machine Learning and Data Science projects. It allows data scientists and developers to create beautiful, interactive web apps quickly and with fewer lines of code. Streamlitâ€™s simplicity and efficiency make it a popular choice for building data-driven web applications without the need for in-depth knowledge of web development frameworks.\n",
        "\n",
        "Flask is a lightweight WSGI (Web Server Gateway Interface) web application framework. It is designed to make getting started with web application development quick and easy, with the ability to scale up to complex applications. Flask provides the tools, libraries, and technologies to build a web application. It allows developers to build web applications in Python, offering flexibility and choice in how the applications are built."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2xY-lT_I9iX"
      },
      "source": [
        "Follow instruction by tutor\n",
        "\n",
        "1) Register Streamlit and link your github account\n",
        "\n",
        "2) Create txt file name requirements, copy the following text into the txt file <br>\n",
        "streamlit\n",
        "joblib\n",
        "numpy\n",
        "scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCsB0DPt9MGH"
      },
      "source": [
        "![Streamlitlogin](streamlitlogin.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIWTeARs9MGH"
      },
      "source": [
        "3) Create another txt file and store the following Streamlit script and save as projectname.py e.g. linear_regression_house_price_prediction.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XC3jprLII_nz"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "from joblib import load\n",
        "import numpy as np\n",
        "\n",
        "# Load the model\n",
        "model = load('linear_regression_model.joblib')\n",
        "\n",
        "# Create a simple user input\n",
        "user_input = st.number_input('Enter house size:', min_value=100, max_value=10000, step=50)\n",
        "\n",
        "# Reshape the input for the model\n",
        "input_array = np.array([user_input]).reshape(-1, 1)\n",
        "\n",
        "# Predict the house price\n",
        "if st.button('Predict Price'):\n",
        "    predicted_price = model.predict(input_array)\n",
        "    st.write(f\"The predicted house price is: ${predicted_price[0]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbNuwFjcJDT6"
      },
      "source": [
        "4) Upload the 2 files which are: requirements.txt and linear_regression_house_price_prediction.py into github and deploy using streamlit. Follow instruction from tutor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ms2QHCEJKUe"
      },
      "source": [
        "# <font color=\"blue\"> Project 2: House Price Prediction (2 features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvJjmAFG_M11"
      },
      "source": [
        "In the previous example, we used only one feature, which was the house size, to predict the house prices. This is called a univariate regression. To improve the model's performance, we can use multiple features, which is called a multivariate regression.\n",
        "\n",
        "For instance, we can use additional features like the number of bedrooms, location, age of the house, etc., to make a more accurate prediction of the house prices. Using more relevant features often leads to better predictions.\n",
        "\n",
        "Here's an example of how you can modify the previous code to use two features (house size and number of bedrooms) to predict house prices:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSrwuJ7c_M12"
      },
      "outputs": [],
      "source": [
        "import                                          #complete this\n",
        "from sklearn.model_selection import          #complete this\n",
        "from sklearn.linear_model import          #complete this\n",
        "from sklearn.metrics import          #complete this\n",
        "\n",
        "# Sample dataset: house sizes and number of bedrooms as features, and prices as the target variable\n",
        "house_sizes = np.array([550, 600, 650, 700, 750, 800, 850, 900, 950, 1000])\n",
        "num_bedrooms = np.array([, , , , , , , , , ])                   #complete this\n",
        "prices = np.array([, , , , , , , , , ])         #complete this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBUQZMG3_M12"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as           #complete this\n",
        "from mpl_toolkits.mplot3d import     #complete this\n",
        "\n",
        "# Create a 3D scatter plot\n",
        "fig = plt.figure()\n",
        "ax = fig.                       #complete this\n",
        "\n",
        "# Scatter plot points with house_sizes and num_bedrooms as X and Y, and prices as Z\n",
        "ax.scatter(house_sizes, num_bedrooms, prices, c='', marker='')           #complete this\n",
        "\n",
        "# Labels for axes\n",
        "ax.set_xlabel(' ') #complete this\n",
        "ax.set_ylabel(' ') #complete this\n",
        "ax.set_zlabel(' ') #complete this\n",
        "\n",
        "# Add dotted lines from data points to respective values on X and Y axes\n",
        "for i in range(len(house_sizes)):\n",
        "    ax.plot([house_sizes[i], house_sizes[i]], [num_bedrooms[i], num_bedrooms[i]], [0, prices[i]], c='gray', linestyle='dotted', alpha=0.5)\n",
        "    ax.plot([house_sizes[i], house_sizes[i]], [0, num_bedrooms[i]], [prices[i], prices[i]], c='gray', linestyle='dotted', alpha=0.5)\n",
        "    ax.plot([0, house_sizes[i]], [num_bedrooms[i], num_bedrooms[i]], [prices[i], prices[i]], c='gray', linestyle='dotted', alpha=0.5)\n",
        "\n",
        "plt.title('House Prices vs. House Sizes and Number of Bedrooms')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3G-fUOl1_M12"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import  #complete this\n",
        "\n",
        "# Combine the two features into a single feature matrix X\n",
        "X = np. ((house_sizes, num_bedrooms))                         #complete this\n",
        "print(\"Feature matrix X:\\n\", X)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test =  (X, prices, test_size= , random_state= )   #complete this\n",
        "\n",
        "# Create the linear regression model\n",
        "model =   #complete this\n",
        "\n",
        "# Train the model using the training data\n",
        "model.    #complete this\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred =  #complete this\n",
        "\n",
        "# Display the values with two decimal places using string formatting\n",
        "formatted_X_test = np.array([[\"%.2f\" % x[0], \"%.2f\" % x[1]] for x in X_test])\n",
        "formatted_y_pred = [\"%.2f\" % y for y in y_pred]\n",
        "\n",
        "print(\"Formatted X_test:\")\n",
        "print(formatted_X_test)\n",
        "\n",
        "print(\"Formatted y_pred:\")\n",
        "print(formatted_y_pred)\n",
        "\n",
        "# Compute and display Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "formatted_mse = \"%.2f\" % mse\n",
        "print(f\"Mean Squared Error: {formatted_mse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDT6pEhA9MGJ"
      },
      "outputs": [],
      "source": [
        "house_size =      #complete this\n",
        "num_bedrooms =  #complete this\n",
        "\n",
        "# Create a feature array for the input\n",
        "input_features = np.array([[house_size, num_bedrooms]])\n",
        "print(input_features)\n",
        "\n",
        "# Predict the price using the trained model\n",
        "predicted_price = model.predict(input_features)[0]\n",
        "\n",
        "# Display the predicted price\n",
        "print(f\"Predicted price for a house with size {house_size} sq ft and {num_bedrooms} bedrooms is (RM): {predicted_price:,.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYeGeeAa_M13"
      },
      "source": [
        "# <font color=\"blue\"> Project 3: Spam Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T-8Lyzg_M13"
      },
      "source": [
        "## Step 1: Prepare the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoZh8Zqo_M13"
      },
      "outputs": [],
      "source": [
        "# make sure the data is labeled\n",
        "import pandas as pd\n",
        "data = pd.read_table('',encoding='windows-1252', header=None)              #complete this\n",
        "data.columns = ['', '']          #complete this\n",
        "print(data.head())\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BL7xpjnm_M13"
      },
      "outputs": [],
      "source": [
        "# remove words with numbers, punctuation and capital letters\n",
        "import   #complete this\n",
        "import   #complete this\n",
        "\n",
        "alphanumeric = lambda x:        #complete this\n",
        "punc_lower = lambda x:      #complete this\n",
        "\n",
        "data['text'] = data.text.map(alphanumeric).map(punc_lower) #complete this\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vlec3iHj_M14"
      },
      "source": [
        "## Step 2: Split the data (into training and testing set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17gs2b4B_M14"
      },
      "source": [
        "<Font color=\"Blue\">__Input__: Features, Predictors, Independent Variables, X's\n",
        "<Font color=\"orange\">__Outputs__: Label, Outcome, Dependent Variable, Y\n",
        "    \n",
        "![](https://i163.photobucket.com/albums/t281/kyin_album/m2.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnXJffXG_M14"
      },
      "outputs": [],
      "source": [
        "# split the data into feature and label\n",
        "X = data.     #complete this\n",
        "y = data.    #complete this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCRkjjgO_M14"
      },
      "outputs": [],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlwtMIGM_M15"
      },
      "outputs": [],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf0fW6-Z_M15"
      },
      "source": [
        "## Overfitting\n",
        "\n",
        "![](https://i163.photobucket.com/albums/t281/kyin_album/m3.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0kr3xpT_M15"
      },
      "source": [
        "![](https://i163.photobucket.com/albums/t281/kyin_album/m4.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PojygMv-_M15"
      },
      "source": [
        "# Split the data [Code]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fF3L8xn_M15"
      },
      "outputs": [],
      "source": [
        "# split the data into a training and test set\n",
        "from sklearn.model_selection import            #complete this\n",
        "X_train, X_test, y_train, y_test =             #complete this\n",
        "\n",
        "# test size = 30% of observations, which means training size = 70% of observations\n",
        "# random state = 42, so we all get the same random train / test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3D6j4b8__M16"
      },
      "outputs": [],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sb9orvle_M16"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbcwZ-8V_M16"
      },
      "outputs": [],
      "source": [
        "y_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzoVCOcN_M16"
      },
      "outputs": [],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUxZZ_K3_M2P"
      },
      "outputs": [],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lilnFM5u_M2Q"
      },
      "outputs": [],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GnESdi9_M2Q"
      },
      "source": [
        "## Step 3: Numerically encode the input data [Code]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILF9pyie_M2Q"
      },
      "outputs": [],
      "source": [
        "from                                               #complete this\n",
        "cv = (stop_words='')                   #complete this\n",
        "X_train_cv =                          #complete this\n",
        "X_test_cv =                           #complete this\n",
        "\n",
        "# print the dimensions of the training set (text messages, terms)\n",
        "print(X_train_cv.toarray().shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdZ9IATp9MGS"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "joblib.dump(cv, 'countvectorizer.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uT9OC-fy_M2R"
      },
      "outputs": [],
      "source": [
        "type(X_train_cv)\n",
        "import scipy.sparse\n",
        "pd.DataFrame.sparse.from_spmatrix(X_test_cv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-g-pB0L_M2R"
      },
      "outputs": [],
      "source": [
        "help(cv.fit_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS3Im8c0_M2R"
      },
      "source": [
        "## Step 4: Fit model and predict outcomes [Code]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekdoA8rf_M2R"
      },
      "outputs": [],
      "source": [
        "# Use a logistic regression model (categorical)\n",
        "from sklearn.linear_model import    #complete this\n",
        "lr =                               #complete this\n",
        "\n",
        "# Train the model\n",
        "lr.                             #complete this\n",
        "\n",
        "# Take the model that was trained on the X_train_cv data and apply it to the X_test_cv\n",
        "y_pred_cv = lr.                 #complete this\n",
        "y_pred_cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ho44bYOM9MGT"
      },
      "outputs": [],
      "source": [
        "joblib.dump(lr, 'logistic_regression_model.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCHg9Bdm_M2S"
      },
      "source": [
        "## Step 5: Evaluate the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPds_0Yc_M2S"
      },
      "source": [
        "![](https://i163.photobucket.com/albums/t281/kyin_album/m5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hir46DGX_M2S"
      },
      "source": [
        "# Step 5: Evaluate the model [Code]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3KZwwpH_M2S"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix  #complete this\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#Provided you are running IPython, the %matplotlib inline will make your plot outputs appear and be stored within the notebook\n",
        "cm = confusion_matrix(y_test, y_pred_cv)   #y_test is the label of testing data, y_pred_cv is the predicted ans from the ML with testing set\n",
        "print(cm[0])\n",
        "print(cm[1])\n",
        "sns.heatmap(cm, xticklabels=['predicted_ham', 'predicted_spam'], yticklabels=['actual_ham', 'actual_spam'], annot=True, fmt='d', annot_kws={'fontsize':20}, cmap=\"YlGnBu\");\n",
        "true_neg, false_pos = cm[0]\n",
        "false_neg, true_pos = cm[1]\n",
        "\n",
        "accuracy = round((true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg),3)\n",
        "precision = round((true_pos) / (true_pos + false_pos),3)\n",
        "recall = round((true_pos) / (true_pos + false_neg),3)\n",
        "f1 = round(2 * (precision * recall) / (precision + recall),3)\n",
        "print('Accuracy: {}'.format(accuracy))\n",
        "print('Precision: {}'.format(precision))\n",
        "print('Recall: {}'.format(recall))\n",
        "print('F1 Score: {}'.format(f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muhACP9j_M2S"
      },
      "source": [
        "## Step 6: Predict new input [Code]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyI1BQfT_M2S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pandas import                     #complete this\n",
        "Sentence1 = [\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st\"]\n",
        "\n",
        "Snew = cv.                      #complete this\n",
        "result = lr.                       #complete this\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBrwdu73_M2T"
      },
      "source": [
        "# <font color=\"blue\"> __Naive Bayes__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQQD4dNg_M2T"
      },
      "source": [
        "# Naive Bayes [code]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VEvQxB8_M2T"
      },
      "outputs": [],
      "source": [
        "# Use a Naive Bayes model\n",
        "from sklearn.naive_bayes import         #complete this\n",
        "import numpy as np\n",
        "nb = MultinomialNB()\n",
        "\n",
        "# Train the model\n",
        "                           #complete this\n",
        "\n",
        "# Take the model that was trained on the X_train_cv data and apply it to the X_test_cv\n",
        "                           #complete this\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfxP9z8f_M2T"
      },
      "source": [
        "# Naive Bayes: Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXAXX1Yu_M2T"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_pred_cv_nb)\n",
        "sns.heatmap(cm, xticklabels=['predicted_ham', 'predicted_spam'], yticklabels=['actual_ham', 'actual_spam'],\n",
        "annot=True, fmt='d', annot_kws={'fontsize':20}, cmap=\"YlGnBu\");\n",
        "true_neg, false_pos = cm[0]\n",
        "false_neg, true_pos = cm[1]\n",
        "accuracy = round((true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg),3)\n",
        "precision = round((true_pos) / (true_pos + false_pos),3)\n",
        "recall = round((true_pos) / (true_pos + false_neg),3)\n",
        "f1 = round(2 * (precision * recall) / (precision + recall),3)\n",
        "print('Accuracy: {}'.format(accuracy))\n",
        "print('Precision: {}'.format(precision))\n",
        "print('Recall: {}'.format(recall))\n",
        "print('F1 Score: {}'.format(f1))\n",
        "\n",
        "NBscore = nb.score(X_test_cv, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjZKpaYB_M2U"
      },
      "source": [
        "# <font color=\"blue\"> Project 4: Review Rating Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OE_TXd4P_M2U"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIpt2oBc_M2U"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VngrUEeE_M2U"
      },
      "source": [
        "# Question 1\n",
        "\n",
        "- Determine how many reviews there are in total.\n",
        "\n",
        "\n",
        "Use the preprocessing code below to clean the reviews data before moving on to modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4rA-xhA_M2V"
      },
      "outputs": [],
      "source": [
        "# Text preprocessing steps - remove numbers, captial letters and punctuation\n",
        "import re\n",
        "import string\n",
        "\n",
        "alphanumeric =          #complete this\n",
        "punc_lower =            #complete this\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXewp_k2_M2V"
      },
      "outputs": [],
      "source": [
        "type(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zJ7gQiN_M2V"
      },
      "source": [
        "# Question 2: Classsification *(20% testing, 80% training)*\n",
        "\n",
        "Processes for classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DzMCwA6_M2V"
      },
      "source": [
        "### <font color=\"Blue\">Step 1:</font> Prepare the data (identify the feature and label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QmNMBni_M2V"
      },
      "outputs": [],
      "source": [
        "# split the data into feature and label\n",
        "X = data.                  #complete this\n",
        "y = data.                   #complete this\n",
        "\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKAs3CwM_M2W"
      },
      "source": [
        "### <font color=\"Blue\">Step 2:</font> Split the data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWwVTj6h_M2W"
      },
      "outputs": [],
      "source": [
        "# split the data into a training and test set\n",
        "from sklearn.model_selection import                    #complete this\n",
        "X_train, X_test, y_train, y_test =                      #complete this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9dCTtWg_M2W"
      },
      "outputs": [],
      "source": [
        "X_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBkN1yoN_M2W"
      },
      "outputs": [],
      "source": [
        "y_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvxHPOF4_M2W"
      },
      "source": [
        "### <font color=\"Blue\">Step 3:</font> Vectorize the feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXd0Li3o_M2X"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import              #complete this\n",
        "cv = CountVectorizer(stop_words='')                       #complete this\n",
        "X_train_cv =                                                 #complete this\n",
        "X_test_cv =                                                #complete this\n",
        "\n",
        "# print the dimensions of the training set (text messages, terms)\n",
        "print(X_train_cv.toarray().shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFAhXYDS_M2X"
      },
      "source": [
        "### <font color=\"Blue\">Step 4:</font> Idenfity the model/ classifier to be used. Feed the train data into the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0wGpeSV_M2X"
      },
      "source": [
        "### - Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBdyQv2r_M2X"
      },
      "outputs": [],
      "source": [
        "# Use a linear regression model\n",
        "from sklearn.linear_model import      #complete this\n",
        "lr = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "                    #complete this\n",
        "\n",
        "# Take the model that was trained on the X_train_cv data and apply it to the X_test_cv\n",
        "                   #complete this\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Up9NiksJ_M2Y",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Use a logistic regression model\n",
        "from sklearn.linear_model import                  #complete this\n",
        "lr = LogisticRegression()\n",
        "\n",
        "# Train the model\n",
        "                   #complete this\n",
        "\n",
        "# Take the model that was trained on the X_train_cv data and apply it to the X_test_cv\n",
        "                   #complete this"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob4vtOQG_M2Y"
      },
      "source": [
        "### - SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLTWggkm_M2Y"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import              #complete this\n",
        "svc = LinearSVC()\n",
        "\n",
        "# Train the model\n",
        "              #complete this\n",
        "\n",
        "# Take the model that was trained on the X_train_cv data and apply it to the X_test_cv\n",
        "               #complete this\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7wMHaSm_M2Y"
      },
      "source": [
        "### - Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XooN2C_8_M2Y"
      },
      "outputs": [],
      "source": [
        "from sklearn import                       #complete this\n",
        "tree = tree.DecisionTreeClassifier()\n",
        "\n",
        "# Train the model\n",
        "                     #complete this\n",
        "\n",
        "# Take the model that was trained on the X_train_cv data and apply it to the X_test_cv\n",
        "                 #complete this"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgKC-BuN_M2Z"
      },
      "source": [
        "### - Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lm5lN875_M2Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import      #complete this\n",
        "forest = RandomForestClassifier(max_depth=10, random_state=0)\n",
        "\n",
        "# Train the model\n",
        "                      #complete this                  #complete this\n",
        "\n",
        "# Take the model that was trained on the X_train_cv data and apply it to the X_test_cv\n",
        "                  #complete this"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az5rD363_M2Z"
      },
      "source": [
        "### - KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7d7ZhSD_M2Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import                 #complete this\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Train the model\n",
        "  #complete this\n",
        "\n",
        "# Take the model that was trained on the X_train_cv data and apply it to the X_test_cv\n",
        "  #complete this"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN4NMmrq_M2Z"
      },
      "source": [
        "### -  Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBPs-aia_M2a"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import  #complete this\n",
        "import numpy as np\n",
        "nb = MultinomialNB()\n",
        "\n",
        "# Train the model\n",
        "#complete this\n",
        "\n",
        "# Take the model that was trained on the X_train_cv data and apply it to the X_test_cv\n",
        "#complete this"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvD9FyXf_M2a"
      },
      "source": [
        "### <font color=\"Blue\">Step 5:</font> Evaluate the Model - Accuracy Measurement\n",
        "Generate the accuracy scores for Linear Regression, SVM, Decision Tree, Random Forest, KNN, and Naive Bayes.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-ib3bZ2_M2a"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import                   #complete this\n",
        "lra = accuracy_score(y_test, y_pred_LR)\n",
        "svm = accuracy_score(y_test, y_pred_svm)\n",
        "dt = accuracy_score(y_test, y_pred_dt)\n",
        "rf = accuracy_score(y_test, y_pred_rf)\n",
        "knn = accuracy_score(y_test, y_pred_knn)\n",
        "nb = accuracy_score(y_test, y_pred_nb)\n",
        "\n",
        "print(\"Accuracy score for LR: %.2f\" % lra)\n",
        "print(\"Accuracy score for SVM: %.2f\" % svm)\n",
        "print(\"Accuracy score for DT: %.2f\" % dt)\n",
        "print(\"Accuracy score for RF: %.2f\" % rf)\n",
        "print(\"Accuracy score for KNN: %.2f\" % knn)\n",
        "print(\"Accuracy score for NB: %.2f\" % nb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTTf68iW_M2a"
      },
      "source": [
        "__Example Output:__\n",
        "- Accuracy score for LR  = 0.1651\n",
        "- Accuracy score for SVM = 0.5413\n",
        "- Accuracy score for DT  = 0.5505\n",
        "- Accuracy score for RF  = 0.5872\n",
        "- Accuracy score for KNN = 0.5963\n",
        "- Accuracy score for NB  = 0.6514"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1yxEuUd_M2b"
      },
      "source": [
        "# Question 3\n",
        "Predict the rate of this review,\n",
        "\n",
        "<font color=\"blue\">__\"like Cafe Vienna instant coffee products with the convenience of Keurig. All authorized on-line sellers cannot carry them\"__\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke-mMhKX_M2b"
      },
      "source": [
        "by using Linear Regression, SVM, Decision Tree, Random Forest, KNN, and Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGrDnUYw_M2b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "# S0 = [\"I dislike this coffee, terrible taste and very greasy.\"]\n",
        "# S1 = [\"This has to be the worst tasting coffee.this is the by far the worst. Don't waste your money on this product.\"]\n",
        "S2 = [\"like Cafe Vienna instant coffee products with the convenience of Keurig. All authorized on-line sellers cannot carry them \"]\n",
        "\n",
        "Snew = cv.transform(S2)\n",
        "lry = lr.predict(Snew)\n",
        "print(lry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjaE6Wv4_M2b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "\n",
        "# Take user input\n",
        "user_input =                               #complete this\n",
        "\n",
        "Snew = cv.                                #complete this\n",
        "lry = lr.                                #complete this\n",
        "print(\"Predicted Label:\", lry[0])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}